\section{Results}
\label{sec:results}

% 3-4 queries 
% Human made ontology 
% Topic Models 

First, we built an ontology for the vehicular realm exploiting the Wikipedia pages, categories, and WordNet synsets. For each of the classes in the ontolgy we built corpora from the corresponding Wikipedia pages. Figure \ref{fig:vehicular_ontology} shows a subsection of this ontology.

%describes the question answering process for the user query, ``A 1997 Toyota Camry V6 needs what size tires?''


%% TODO - need to refer back to the table which is figure one.
%The Morpheus NLP engine parses this query into the constructs: WH:what, Descriptive Information:1997 Toyota Camry V6, Asking For:size tires. From the descriptive info, we generate the N-grams or terms 1997, 1997 Toyota, 1997 Toyota Camry,Toyota,Toyota Camry,Toyota Camry V6, Camry, Camry V6, and V6. For each of the terms, we determined relevant categories (non-increasing order of relevance) from the ontology corpora. Table \ref{tbl:term_categories} shows the top categories and their probabilities for each of the query term.
In Table \ref{tbl:nlp_engine_parse} we show the data that is output by the Morpheus NLP engines parse of the query .  It extracts the WH question, that is, the the term that identifies the sentence as a question.  Next, the engine locates the descriptive information that can be used to describe the answer. Then the engine extracts the terms that describe what is being requested. Finally, the engine produces n-grams from the terms in the descriptive information sections.

Using the data in \ref{tbl:nlp_engine_parse} we determined relevant classes (non-increasing order of relevance) from the ontology given each n-gram. Table \ref{tbl:term_categories} shows the top classes and their probabilities for our example.


\begin{table}[h]\footnotesize
	\begin{tabular}{|l|p{4.2cm}|}
		\hline 
		WH & what \\
		\hline 
		Descriptive Information & 1997 Toyota Camry V6 \\
		\hline 
		Asking for & size tires \\
		\hline 
		n-grams & 1997, 1997 Toyota, 1997 Toyota Camry, Toyota, Toyota Camry, Toyota Camry V6, Camry, Camry V6, V6 \\
		\hline
	\end{tabular}
	\caption{The output of NLP engine parse}
	\label{tbl:nlp_engine_parse} 
\end{table}

\begin{table}[h]\footnotesize

\begin{tabular}{| p{3.2cm} | l | r |}
\hline 
Term & Category & $P(Category|Term)$ \\ \hline
1997 & Sedans & 404132.77e-14\\ 
1997 Toyota & Engines & 7.90e-14\\ 
Toyota  & Sedans & 3486670.15e-14\\ 
Toyota Camry & Sedans & 12147.23e-14\\ 
Toyota Camry V6 & Coupes & 13.80e-14\\ 
Camry & Sedans & 312034.20e-14\\ 
Camry V6 & Coupes & 13.80e-14\\ 
V6 & Sedans & 4464535.40e-14\\ \hline
\end{tabular}        

\caption{Terms' top categories and probabilities}
\label{tbl:term_categories}   

\end{table}

We found the top category of the terms in the candidate SSQ and determined the category divergence with the qualified SSQ classes in the QRM store. Then, we combined the divergence measure and
ranked QRMs based on the relevance score. Table \ref{tbl:ranked_queries} shows the top ranked SSQ for the query.  Finally, we execute the selected QRM and display the results to the user.

\begin{table}[h]\footnotesize

\begin{tabular}{| p{3.5cm} | p{3cm} | r |}
	\hline
	Query & Tagged Classes & Score\\ 
	\hline
	A 1997 Toyota Camry V6 needs what size tires? & inputs(Sedans, Cars, Engines, Manufactures) & 0.91\\ 
	\hline 
	What is the tire size for a 1998 Sienna XLE Van? & inputs(1998 Toyota Sienna XLE Van: Vans, Toyota : Manufacturers) & 0.72\\ 	\hline 
	Where can I buy an engine for a Toyota Camry V6? & inputs(Toyota Camry : Sedans, Toyota Camry V6 : Automobile_Engines, Toyota : Manufacturers) & 0.74 \\
	\hline 
%What is the cost of a Toyota Camry V6 muffler? &  IC:Manufactures, Sedans, Engines OC: the clost  & 0.97 \\ \hline
\end{tabular}

\caption{Top ranked queries and relevance scores: IC - input classes, OC - output classes}
\label{tbl:ranked_queries}   

\end{table}


%\subsection{Discussion}
\section{Conclusion}

In this paper, we propose a novel question answering system that uses the deep web and previously answered user queries to answer similar questions. The system uses a path-finder to annotate answer paths so path-followers can discover answers to similar questions.  Each $(question, answer)$ pair is assigned a realm, and new questions are matched to the new $(question, answer)$ pairs. Classification of terms into classes is based on term frequency distributions in our corpora of web documents. We are investigating improvements to our solution by an approach similar to Topic Models \cite{Blei2003latentdirichlet}. 

Manually forming a corpus of wilipedia pages associated with a class is a cumbersome task. Topic Modeling provides a promising approach to identifying pages relevent to given class in a more automated manner.
%The Wikipedia page categories has limitations. Without supervision, the page categorization is often a challenging problem, because topics in the pages that belong to a realm (e.g. vehicular) usually overlap. So we are evaluating the applicability of probabilistic topic models to web page categorization, and automatic generation of a realm-ontology based on the topics being extracted.
 


% 2. Current stage of the project 
% 3. Expected contribution to the topics of interest supported by iiWAS2010 
